slug: "interpreter"
name: "Build your own Interpreter"
short_name: "Interpreter"
release_status: "alpha"

description_md: |-
  This challenge follows the book [Crafting Interpreters](https://craftinginterpreters.com/) by Robert Nystrom.

  In this challenge you'll build an interpreter for [Lox](https://craftinginterpreters.com/the-lox-language.html), a simple scripting
  language. Along the way, you'll learn about tokenization, ASTs, tree-walk interpreters and more.

  Before starting this challenge, make sure you've read the "Welcome" part of the book that contains these chapters:

  - [Introduction](https://craftinginterpreters.com/introduction.html) (chapter 1)
  - [A Map of the Territory](https://craftinginterpreters.com/a-map-of-the-territory.html) (chapter 2)
  - [The Lox Language](https://craftinginterpreters.com/the-lox-language.html) (chapter 3)

  These chapters don't involve writing code, so they won't be covered in this challenge. This challenge will start
  from chapter 4, [Scanning](https://craftinginterpreters.com/scanning.html).

short_description_md: |-
  Learn about tokenization, ASTs, tree-walk interpreters and more.

completion_percentage: 15

languages:
  - slug: "go"
  - slug: "python"
  - slug: "rust"

marketing:
  difficulty: hard
  sample_extension_idea_title: "Control flow"
  sample_extension_idea_description: "An interpreter that can handle control flow statements like if/else"
  testimonials:
    - author_name: "Ananthalakshmi Sankar"
      author_description: "Automation Engineer at Apple"
      author_avatar: "https://codecrafters.io/images/external/testimonials/oxta.jpeg"
      link: "https://github.com/anu294"
      text: "There are few sites I like as much that have a step by step guide. The real-time feedback is so good, it's creepy!"

    - author_name: "Patrick Burris"
      author_description: "Senior Software Developer, CenturyLink"
      author_avatar: "https://codecrafters.io/images/external/testimonials/patrick-burris.jpeg"
      link: "https://github.com/Jumballaya"
      text: |-
        I think the instant feedback right there in the git push is really cool.
        Didn't even know that was possible!

stages:
  - slug: "ry8"
    name: "Scanning: Empty file"
    difficulty: very_easy
    description_md: |-
      Before starting this stage, make sure you've read the "Welcome" section of the book that contains these chapters:

      - [Introduction](https://craftinginterpreters.com/introduction.html) (chapter 1)
      - [A Map of the Territory](https://craftinginterpreters.com/a-map-of-the-territory.html) (chapter 2)
      - [The Lox Language](https://craftinginterpreters.com/the-lox-language.html) (chapter 3)

      These chapters don't involve writing code, so they won't be covered in this challenge. This challenge will start
      from chapter 4, [Scanning](https://craftinginterpreters.com/scanning.html).

      ---

      In this stage, you'll implement basic support for the `tokenize` command.

      ### The `tokenize` command

      The `tokenize` command tokenizes a Lox program and prints the tokens to stdout. We'll use this for testing
      all stages in the [Scanning](https://craftinginterpreters.com/scanning.html) chapter.

      If there's a file named `test.lox` with the following contents:

      ```
      var language = "lox";
      ```

      The `tokenize` command will return the following:

      ```
      $ ./your_program.sh tokenize test.lox
      VAR var null
      IDENTIFIER language null
      EQUAL = null
      STRING "lox" lox
      SEMICOLON ; null
      EOF  null
      ```

      This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning).

      Each line corresponds to a token in the file (Image from [Section 4.2: Lexemes & Tokens](https://craftinginterpreters.com/scanning.html#lexemes-and-tokens)):

      ![img](https://craftinginterpreters.com/image/scanning/lexemes.png)

      This is the format for each line:

      ```
      <token_type> <lexeme> <literal>
      ```

      - `<token_type>`: The type of the token.
        - Examples: `VAR`, `IDENTIFIER`, `STRING`, `EOF` etc.
      - `<lexeme>`: The actual sequence of characters that formed the token.
        - Examples: `var`, `breakfast`, `"bagels"` etc.
        - For an `EOF` token, the lexeme is an empty string.
      - `<literal>`: The literal value of the token.
        - For most tokens this is `null`.
        - For `STRING`/`NUMBER` tokens, it holds the value of the string/number.

      The `EOF` token is a special token that represents the end of the file. All calls to `tokenize` will include an `EOF` token at the end.

      ### Tests

      The tester will write an empty file to `test.lox`. It'll then run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      EOF  null
      ```

      Since the file is empty, only one token is expected in the output: `EOF`. The tester will verify that `EOF<space><space>null` is printed to stdout.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - There are two spaces between `EOF` and `null`. This is because the `<lexeme>` part is an empty string for the `EOF` token.
    marketing_md: |-
      In this stage, you'll implement basic support for the `tokenize` command which we'll use in all stages that are part of the [Scanning](https://craftinginterpreters.com/scanning.html) chapter.

  - slug: "ol4"
    name: "Scanning: Parentheses"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for scanning parentheses.

      ### Book reference

      The code for this stage is implemented in [Section 4.5: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain parentheses.

      For example, if `test.lox` contains the following:

      ```
      (()
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      LEFT_PAREN ( null
      LEFT_PAREN ( null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning parentheses.

  - slug: "oe8"
    name: "Scanning: Braces"
    difficulty: easy
    description_md: |-
      In this stage, you'll add support for scanning braces.

      ### Book reference

      The code for this stage is implemented in [Section 4.5: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain braces combined with parentheses.

      For example, if `test.lox` contains the following:

      ```
      {{}}
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      LEFT_BRACE { null
      LEFT_BRACE { null
      RIGHT_BRACE } null
      RIGHT_BRACE } null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning braces.

  - slug: "xc5"
    name: "Scanning: Other single-character tokens"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning other single-character tokens, like ",", ".", "-", "+", ";", "*".
      "/" is not covered here, it's coved in later stages. 

      ### Book reference

      The code for this stage is implemented in [Section 4.5: Recognizing Lexemes](https://craftinginterpreters.com/scanning.html#recognizing-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain parentheses, braces combined with all the new single-character tokens.

      For example, if `test.lox` contains the following:

      ```
      ({*.,+*})
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      LEFT_PAREN ( null
      LEFT_BRACE { null
      STAR * null
      DOT . null
      COMMA , null
      PLUS + null
      STAR * null
      RIGHT_BRACE } null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning other single-character tokens.

  - slug: "ea6"
    name: "Scanning: Lexical errors"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning tokens, that lead to a lexical error.

      ### Book reference

      The code for this stage is implemented in [Section 4.5.1: Lexical Errors](https://craftinginterpreters.com/scanning.html#lexical-errors).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain unknown tokens mixed with other previously introduced token types.

      For example, if `test.lox` contains the following:

      ```
      ,.$(#
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      [line 1] Error: Unexpected character: $
      [line 1] Error: Unexpected character: #
      COMMA , null
      DOT . null
      LEFT_PAREN ( null
      EOF  null
      ```

      The lexical errors, should be printed to the stderr stream, with the `[line N]` prefix at the beginning. 
      The tester will assert that the stdout stream of your program matches the valid tokens, and the stderr stream contains the lexical errors. 
      The tester will also assert that the exit code is non-zero, or more specifically 65 in case of lexical errors.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
      - You can use the stderr stream to print debug logs for your own use too, to register a line as an error, it has to contain the `[line N]` prefix. Else we will ignore it as an user log. 
      - As the stdout and stderr are completely different streams, the order of errors and valid tokens don't matter. 
    marketing_md: |-
      In this stage, you'll implement support for scanning lexical errors.

  - slug: "mp7"
    name: "Scanning: Assignment & equality Operators"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning assignment & equality operators.

      ### Book reference

      The code for this stage is implemented in [Section 4.5.2: Operators](https://craftinginterpreters.com/scanning.html#operators).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain equality & assignment operators mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      ={===}
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      EQUAL = null
      LEFT_BRACE { null
      EQUAL_EQUAL == null
      EQUAL = null
      RIGHT_BRACE } null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning the assignment & equality operators.

  - slug: "bu3"
    name: "Scanning: Negation & inequality operators"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning negation & inequality operators.

      ### Book reference

      The code for this stage is implemented in [Section 4.5.2: Operators](https://craftinginterpreters.com/scanning.html#operators).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain inequality & negation operators mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      !!===
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      BANG ! null
      BANG_EQUAL != null
      EQUAL_EQUAL == null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning negation & inequality operators.

  - slug: "et2"
    name: "Scanning: Relational operators"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning relational operators, which are: "<", ">", "<=", ">=".

      ### Book reference

      The code for this stage is implemented in [Section 4.5.2: Operators](https://craftinginterpreters.com/scanning.html#operators).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain relational operators mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      <<=>>=
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      LESS < null
      LESS_EQUAL <= null
      GREATER > null
      GREATER_EQUAL >= null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning relational operators.

  - slug: "ml2"
    name: "Scanning: Division operator & comments"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning the division operator & comments.
      Comments start with "//", and the division operator is "/".

      ### Book reference

      The code for this stage is implemented in [Section 4.6: Longer Lexemes](https://craftinginterpreters.com/scanning.html#longer-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain "/" & "//" mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      // Comment
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      EOF  null
      ```

      Similarly, if `test.lox` contains the following:

      ```
      /
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      SLASH / null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning the division operator & comments.

  - slug: "er2"
    name: "Scanning: Whitespace"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning whitespaces.

      ### Book reference

      The code for this stage is implemented in [Section 4.6: Longer Lexemes](https://craftinginterpreters.com/scanning.html#longer-lexemes).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain whitespaces mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      (<|TAB|>
      <|SPACE|>)
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      LEFT_PAREN ( null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The `test.lox` file will contain the space character, and tab character, but to take it more readable in logs, we will replace them with `|SPACE|` and `|TAB|` respectively. This will be done ONLY in the logs, the file will contain the actual characters.
      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning whitespaces.

  - slug: "tz7"
    name: "Scanning: Multi-line errors"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning lexical errors, which span multiple lines.

      ### Book reference

      The code for this stage is implemented in [Section 4.5.1: Lexical Errors](https://craftinginterpreters.com/scanning.html#lexical-errors).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain lexical errors spanning multiple lines.

      For example, if `test.lox` contains the following:

      ```
      ()<|SPACE|><|TAB|>@
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      [line 2] Error: Unexpected character: @
      LEFT_PAREN ( null
      RIGHT_PAREN ) null
      EOF  null
      ```

      The tester will assert that the stdout & stderr of your program matches the format above. 
      Pay special attention to the line number in your error strings. 

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning multi-line errors.

  - slug: "ue7"
    name: "Scanning: String literals"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for scanning string literals.

      ### Book reference

      The code for this stage is implemented in [Section 4.6.1: String literals](https://craftinginterpreters.com/scanning.html#string-literals).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain string literals inside double quotes, mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      "foo baz"
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      STRING "foo baz" foo baz
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning string literals.

  - slug: "kj0"
    name: "Scanning: Number literals"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for scanning number literals.

      ### Book reference

      The code for this stage is implemented in [Section 4.6.2: Number literals](https://craftinginterpreters.com/scanning.html#number-literals).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain number literals mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      1234.1234
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      NUMBER 1234.1234 1234.1234
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning number literals.

  - slug: "ey7"
    name: "Scanning: Identifiers"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for scanning identifiers.

      ### Book reference

      The code for this stage is implemented in [Section 4.7: Reserved Words and Identifiers](https://craftinginterpreters.com/scanning.html#reserved-words-and-identifiers).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain identifiers mixed with previously introduced tokens.

      For example, if `test.lox` contains the following:

      ```
      foo bar _hello
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      IDENTIFIER foo null
      IDENTIFIER bar null
      IDENTIFIER _hello null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning identifers.

  - slug: "pq5"
    name: "Scanning: Reserved words"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for scanning reserved words.

      ### Book reference

      The code for this stage is implemented in [Section 4.7: Reserved Words and Identifiers](https://craftinginterpreters.com/scanning.html#reserved-words-and-identifiers).

      ### Tests

      The tester will run a series of tests with `test.lox` files that contain reserved words mixed with other previously introduced token types.

      For example, if `test.lox` contains the following:

      ```
      and
      ```

      The tester will run your program like this:

      ```
      $ ./your_program.sh tokenize test.lox
      AND and null
      EOF  null
      ```

      The tester will assert that the stdout of your program matches the format above.

      ### Notes

      - This output format matches the spec in the [book's repository](https://github.com/munificent/craftinginterpreters/tree/01e6f5b8f3e5dfa65674c2f9cf4700d73ab41cf8/test/scanning)
      - When scanning for tokens, it's valid to have "unbalanced" parentheses or braces. When we get to parsing expressions in later stages, these cases will be highlighted as errors.
    marketing_md: |-
      In this stage, you'll implement support for scanning reserved words.
